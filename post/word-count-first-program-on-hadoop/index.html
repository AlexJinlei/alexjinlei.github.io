<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Word Count — the First Program on Hadoop - This is Flying Cat Alex&#39;s Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="AlexJinlei" />
  <meta name="description" content="In this post, I will talk about how to run the demo program &amp;ldquo;word count&amp;rdquo; in Hadoop environment.
1. Source Code 
" />

  <meta name="keywords" content="Computer Science, Big Data, UAV" />






<meta name="generator" content="Hugo 0.38.2" />


<link rel="canonical" href="https://alexjinlei.github.io/post/word-count-first-program-on-hadoop/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">







<link href="/dist/even.min.css?v=3.1.1" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="Word Count — the First Program on Hadoop" />
<meta property="og:description" content="In this post, I will talk about how to run the demo program &ldquo;word count&rdquo; in Hadoop environment.

1. Source Code

" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://alexjinlei.github.io/post/word-count-first-program-on-hadoop/" />



<meta property="article:published_time" content="2018-03-16T00:00:00-04:00"/>

<meta property="article:modified_time" content="2018-04-15T03:19:19-04:00"/>











<meta itemprop="name" content="Word Count — the First Program on Hadoop">
<meta itemprop="description" content="In this post, I will talk about how to run the demo program &ldquo;word count&rdquo; in Hadoop environment.

1. Source Code

">


<meta itemprop="datePublished" content="2018-03-16T00:00:00-04:00" />
<meta itemprop="dateModified" content="2018-03-16T00:00:00-04:00" />
<meta itemprop="wordCount" content="1770">



<meta itemprop="keywords" content="Hadoop,MapReduce,Big Data," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Word Count — the First Program on Hadoop"/>
<meta name="twitter:description" content="In this post, I will talk about how to run the demo program &ldquo;word count&rdquo; in Hadoop environment.

1. Source Code

"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">FlyingCat</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">FlyingCat</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Word Count — the First Program on Hadoop</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-03-16 </span>
        <div class="post-category">
            
              <a href="/categories/technique/"> Technique </a>
            
          </div>
        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li><a href="#1-source-code">1. Source Code</a></li>
<li><a href="#2-compile-source-code">2. Compile Source Code</a>
<ul>
<li><a href="#create-program-folder">Create program folder:</a></li>
<li><a href="#method-1-compile-via-command-line">Method 1: Compile via Command Line:</a></li>
<li><a href="#method-2-compile-using-makefile">Method 2: Compile using makefile:</a></li>
</ul></li>
<li><a href="#3-create-jar-file">3. Create .jar File</a></li>
<li><a href="#4-put-program-and-input-files-into-hadoop-hdfs-file-system">4. Put Program and Input Files into Hadoop HDFS File System</a></li>
<li><a href="#5-run-hadoop-program">5. Run Hadoop Program</a></li>
<li><a href="#6-check-the-result">6. Check the Result</a></li>
</ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      <p>In this post, I will talk about how to run the demo program &ldquo;word count&rdquo; in Hadoop environment.</p>

<h1 id="1-source-code">1. Source Code</h1>

<p></p>

<pre><code class="language-java">import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

  public static class TokenizerMapper
       extends Mapper&lt;Object, Text, Text, IntWritable&gt;{

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context
                    ) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer(value.toString());
      while (itr.hasMoreTokens()) {
        word.set(itr.nextToken());
        context.write(word, one);
      }
    }
  }

  public static class IntSumReducer
       extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
                       Context context
                       ) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      result.set(sum);
      context.write(key, result);
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf, &quot;word count&quot;);
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}
</code></pre>

<h1 id="2-compile-source-code">2. Compile Source Code</h1>

<h2 id="create-program-folder">Create program folder:</h2>

<pre><code class="language-bash">$ mkdir /Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count
$ mkdir /Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count/classes
$ mkdir /Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count/src
</code></pre>

<p>Name source code as <code>WordCount.java</code>, save it in <code>/src</code> folder that we created in last step.</p>

<p>To compile <code>WordCount.java</code> source code, we need three classes in Hadoop folder, they are:
<pre>
&lt;your-hadoop-home-folder&gt;/share/hadoop/common/hadoop-common-3.0.0.jar
&lt;your-hadoop-home-folder&gt;/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar
&lt;your-hadoop-home-folder&gt;/share/hadoop/common/commons-cli-1.2.jar
</pre>
In this example, my hadoop home folder is <code>/Users/jz0006/GoogleDrive/Hadoop/hadoop-3.0.0</code>
These three classes should be pass to compiler by <code>-classpath</code> flag.</p>

<p>You can either use command line or makefile to compile source code.</p>

<h2 id="method-1-compile-via-command-line">Method 1: Compile via Command Line:</h2>

<p>In terminal, navigate to the program root folder,</p>

<pre><code class="language-bash">$ cd /Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count
</code></pre>

<p>Then run the following command,</p>

<pre><code class="language-bash">$ javac -g -classpath /Users/jz0006/GoogleDrive/Hadoop/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/Users/jz0006/GoogleDrive/Hadoop/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/Users/jz0006/GoogleDrive/Hadoop/hadoop-3.0.0/share/hadoop/common/commons-cli-1.2.jar -d classes/ src/WordCount.java
</code></pre>

<p>The <code>-g</code> flag is to show all debug message, the <code>-classpath</code> flag pass the path of needed classes, the <code>-d</code> flag tell the compiler where to put the compiled file, and the last parameter is the path of source file which is to be compiles.</p>

<p>Then, go to the <code>/classes</code> folder to check the compiling result.</p>

<pre><code class="language-bash">$ cd /Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count/classes
</code></pre>

<p>Your should see three files, <code>WordCount$IntSumReducer.class</code>, <code>WordCount.class</code>, and <code>WordCount$TokenizerMapper.class</code>.</p>

<h2 id="method-2-compile-using-makefile">Method 2: Compile using makefile:</h2>

<pre><code class="language-makefile"># Define compiler.
JC = javac

# Set compiler flag variables.
# -g will print all error message.
# -classpath contains the classes used for compiling the project.
# -d sets the destination path.
JFLAGS = -g -classpath $(HADOOP_HOME)/share/hadoop/common/hadoop-common-3.0.0.jar:$(HADOOP_HOME)/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:$(HADOOP_HOME)/share/hadoop/common/commons-cli-1.2.jar -d $(JCLASSDIR)

# Clear any default targets for building .class files from .java files; we 
# will provide our own target entry to do this in this makefile.
# make has a set of default targets for different suffixes (like .c.o) 
# Currently, clearing the default for .java.class is not necessary since 
# make does not have a definition for this target, but later versions of 
# make may, so it doesn't hurt to make sure that we clear any default 
# definitions for these
.SUFFIXES: .java .class

# Set the pathes of the source files and class files.
SOURCEDIR = src/
JCLASSDIR = classes/

# Here is our target entry for creating .class files from .java files 
# This is a target entry that uses the suffix rule syntax:
# DSTS:
#     rule
# 'TS' is the suffix of the target file, 'DS' is the suffix of the dependency 
# file, and 'rule'  is the rule for building a target.
# '$*' is a built-in macro that gets the basename of the current target 
# Remember that there must be a &lt; tab &gt; before the command line ('rule') 
.java.class:
    $(JC) $(JFLAGS) $*.java

# CLASSES is a macro consisting all java source files.
# If makefile and source file are not in same folder, you have to specify the path.
CLASSES = $(SOURCEDIR)WordCount.java

# The default make target entry
default: classes

# This target entry uses Suffix Replacement within a macro: 
# $(name:string1=string2)
# In the words in the macro named 'name' replace 'string1' with 'string2'
# Below we are replacing the suffix .java of all words in the macro CLASSES 
# with the .class suffix
classes: $(CLASSES:.java=.class)

# RM is a predefined macro in make (RM = rm -f)
clean:
    $(RM) $(JCLASSDIR)*.class
</code></pre>

<p>Note that, in <code>makefile</code>, the tab cannot be replaced by 4 or 8 spaces. If your text editor will convert tab to spaces, disable this function.</p>

<p>Save the code above and name it as makefile. Put this makefile to the folder <code>/Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count</code>. Then cd to this folder, run make command.</p>

<pre><code class="language-bash">$ cd /Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count
$ make
</code></pre>

<p>In terminal, you will see the output:
<pre>
javac -g -classpath /Users/jz0006/GoogleDrive/Hadoop/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/Users/jz0006/GoogleDrive/Hadoop/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/Users/jz0006/GoogleDrive/Hadoop/hadoop-3.0.0/share/hadoop/common/commons-cli-1.2.jar -d classes/ src/WordCount.java
</pre></p>

<h1 id="3-create-jar-file">3. Create .jar File</h1>

<p>Use jar command to put all classes into a .jar file:</p>

<pre><code class="language-bash">$ jar cf ../wc.jar WordCount*.class
</code></pre>

<p>Now the <code>wc.jar</code> file is in the folder <code>/Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count</code>. Go back to the parent folder, you should see this <code>wc.jar</code> file.</p>

<h1 id="4-put-program-and-input-files-into-hadoop-hdfs-file-system">4. Put Program and Input Files into Hadoop HDFS File System</h1>

<p>For our convenience, we are going to create a local folder to put input files.</p>

<pre><code class="language-bash">$ mkdir /Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count/input
</code></pre>

<p>Create to text files under the input folder.</p>

<pre><code class="language-bash">$ &gt;file01.txt
$ &gt;file02.txt
</code></pre>

<p>Open <code>file01.txt</code> use text editor, input: <code>Hello World Bye World</code>.
Open <code>file02.txt</code> use text editor, input: <code>Hello Hadoop Goodbye Hadoop</code>.</p>

<p>Save and close the input files.</p>

<p>Now we are going to create folders in Hadoop file system (HDFS). Note that, the cd command in Linux/Unix system won’t make any sense in Hadoop file system, since Hadoop file system is a virtual file system. You should always provide the full path to access a folder.</p>

<p>Lets check the root folder of your HDFS. In terminal, run:</p>

<pre><code class="language-bash">$ hadoop fs -ls /
</code></pre>

<p>The output in my system is (Please ignore the warning message):</p>

<pre>2018-03-16 15:21:26,693 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 2 items
drwx------   - jz0006 supergroup          0 2018-03-15 05:56 /tmp
drwxr-xr-x   - jz0006 supergroup          0 2018-03-15 05:56 /user
</pre>

<p>It shows that there are two folders under the root path. I’ve already created <code>/user</code> folder. If you haven’t, create it:</p>

<pre><code class="language-bash">$ hadoop fs -mkdir /user
</code></pre>

<p>Then, I create a user named by <code>jz0006</code>:</p>

<pre><code class="language-bash">$ hadoop fs -mkdir /user/jz0006
</code></pre>

<p>Next, we create a folder for our word count program.</p>

<pre><code class="language-bash">$ hadoop fs -mkdir /user/jz0006/wordcount
</code></pre>

<p>Under wordcount folder, we create an input folder to put our input files.</p>

<pre><code class="language-bash">$ hadoop fs -mkdir /user/jz0006/wordcount/input
</code></pre>

<p>In this example, please don’t create output folder. Because the word count program will create output folder by itself. If this folder already exists, an exception will occur. If you run the program for the second time, the output folder will be there already, delete it by typing:</p>

<pre><code class="language-bash">$ hadoop fs -rm -r /user/jz0006/wordcount/output/
</code></pre>

<p>Now it’s the time to put our input files into HDFS. Firstly go to the path where the input files are located.</p>

<pre><code class="language-bash">$ cd /Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count/input
</code></pre>

<p>Then use hadoop command to put the input files into HDFS.</p>

<pre><code class="language-bash">$ hadoop fs -put *.txt /user/jz0006/wordcount/input
</code></pre>

<p>Check it:</p>

<pre><code class="language-bash">$ hadoop fs -ls /user/jz0006/wordcount/input
</code></pre>

<p>Output:
<pre>
2018-03-16 15:40:37,437 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform&hellip; using builtin-java classes where applicable
Found 2 items
-rw-r&ndash;r&ndash;   1 jz0006 supergroup         21 2018-03-16 03:58 /user/jz0006/wordcount/input/file01.txt
-rw-r&ndash;r&ndash;   1 jz0006 supergroup         27 2018-03-16 03:58 /user/jz0006/wordcount/input/file02.txt
</pre>
We can see that the input files are put into HDFS successfully.</p>

<h1 id="5-run-hadoop-program">5. Run Hadoop Program</h1>

<p>Firstly, cd to the folder that contains the <code>.jar</code> file.</p>

<pre><code class="language-bash">$ cd /Users/jz0006/GoogleDrive/Hadoop/my_app/01_word_count
</code></pre>

<p>Then run the command:</p>

<pre><code class="language-bash">$ hadoop jar wc.jar WordCount /user/jz0006/wordcount/input /user/jz0006/wordcount/output
</code></pre>

<p>The terminal output:
<pre>
2018-03-16 15:47:28,758 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform&hellip; using builtin-java classes where applicable
2018-03-16 15:47:29,506 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
2018-03-16 15:47:30,061 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-03-16 15:47:30,075 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jz0006/.staging/job_1521107676874_0016
2018-03-16 15:47:30,283 INFO input.FileInputFormat: Total input files to process : 2
2018-03-16 15:47:30,342 INFO mapreduce.JobSubmitter: number of splits:2
2018-03-16 15:47:30,420 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-03-16 15:47:30,563 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1521107676874_0016
2018-03-16 15:47:30,565 INFO mapreduce.JobSubmitter: Executing with tokens: []
2018-03-16 15:47:30,813 INFO conf.Configuration: resource-types.xml not found
2018-03-16 15:47:30,814 INFO resource.ResourceUtils: Unable to find &lsquo;resource-types.xml&rsquo;.
2018-03-16 15:47:30,924 INFO impl.YarnClientImpl: Submitted application application_1521107676874_0016
2018-03-16 15:47:30,980 INFO mapreduce.Job: The url to track the job: <a href="http://localhost:8088/proxy/application_1521107676874_0016/">http://localhost:8088/proxy/application_1521107676874_0016/</a>
2018-03-16 15:47:30,981 INFO mapreduce.Job: Running job: job_1521107676874_0016
2018-03-16 15:47:38,093 INFO mapreduce.Job: Job job_1521107676874_0016 running in uber mode : false
2018-03-16 15:47:38,095 INFO mapreduce.Job:  map 0% reduce 0%
2018-03-16 15:47:44,190 INFO mapreduce.Job:  map 100% reduce 0%
2018-03-16 15:47:49,226 INFO mapreduce.Job:  map 100% reduce 100%
2018-03-16 15:47:49,232 INFO mapreduce.Job: Job job_1521107676874_0016 completed successfully
2018-03-16 15:47:49,340 INFO mapreduce.Job: Counters: 49
    File System Counters
        FILE: Number of bytes read=79
        FILE: Number of bytes written=615370
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
        HDFS: Number of bytes read=298
        HDFS: Number of bytes written=41
        HDFS: Number of read operations=11
        HDFS: Number of large read operations=0
        HDFS: Number of write operations=2
    Job Counters
        Launched map tasks=2
        Launched reduce tasks=1
        Data-local map tasks=2
        Total time spent by all maps in occupied slots (ms)=7193
        Total time spent by all reduces in occupied slots (ms)=2860
        Total time spent by all map tasks (ms)=7193
        Total time spent by all reduce tasks (ms)=2860
        Total vcore-milliseconds taken by all map tasks=7193
        Total vcore-milliseconds taken by all reduce tasks=2860
        Total megabyte-milliseconds taken by all map tasks=7365632
        Total megabyte-milliseconds taken by all reduce tasks=2928640
    Map-Reduce Framework
        Map input records=2
        Map output records=8
        Map output bytes=82
        Map output materialized bytes=85
        Input split bytes=250
        Combine input records=8
        Combine output records=6
        Reduce input groups=5
        Reduce shuffle bytes=85
        Reduce input records=6
        Reduce output records=5
        Spilled Records=12
        Shuffled Maps =2
        Failed Shuffles=0
        Merged Map outputs=2
        GC time elapsed (ms)=158
        CPU time spent (ms)=0
        Physical memory (bytes) snapshot=0
        Virtual memory (bytes) snapshot=0
        Total committed heap usage (bytes)=647495680
    Shuffle Errors
        BAD_ID=0
        CONNECTION=0
        IO_ERROR=0
        WRONG_LENGTH=0
        WRONG_MAP=0
        WRONG_REDUCE=0
    File Input Format Counters
        Bytes Read=48
    File Output Format Counters
        Bytes Written=41
</pre></p>

<h1 id="6-check-the-result">6. Check the Result</h1>

<p>Firstly, let’s check what’s in the output folder:</p>

<pre><code class="language-bash">$ hadoop fs -ls /user/jz0006/wordcount/output
</code></pre>

<p>Output is:
<pre>
2018-03-16 15:50:43,420 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform&hellip; using builtin-java classes where applicable
Found 2 items
-rw-r&ndash;r&ndash;   1 jz0006 supergroup          0 2018-03-16 15:47 /user/jz0006/wordcount/output/_SUCCESS
-rw-r&ndash;r&ndash;   1 jz0006 supergroup         41 2018-03-16 15:47 /user/jz0006/wordcount/output/part-r-00000
</pre>
The result is in the file <code>part-r-00000</code>. Let&rsquo;s look into this file using cat command:</p>

<pre><code class="language-bash">$ hadoop fs -cat /user/jz0006/wordcount/output/part-r-00000
</code></pre>

<p>You will see:</p>

<pre>
2018-03-16 15:52:48,570 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Bye     1
Goodbye 1
Hadoop  2
Hello   2
World   2
</pre> 

<p>We can see that each word in the two input files are counted correctly.</p>
    </div>

    
    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">AlexJinlei</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">2018-04-15</span>
  </p>
  
  
</div>

    
    

    <footer class="post-footer">
      <div class="post-tags">
          
          <a href="/tags/hadoop/">Hadoop</a>
          
          <a href="/tags/mapreduce/">MapReduce</a>
          
          <a href="/tags/big-data/">Big Data</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/hadoop-demo-max-global-temperature/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Max Global Temperature — Another Hadoop Demo Program</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/install-hadoop-3-0-0-on-macos-high-sierra-10-13-3/">
            <span class="next-text nav-default">Install Hadoop 3.0.0 on macOS High Sierra 10.13.3</span>
            <span class="prev-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="disqus_thread"></div>
<script>





(function() { 
var d = document, s = d.createElement('script');
s.src = 'https://alexjinlei.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>




  <div id="disqus_thread"></div>
    <script type="text/javascript">
    (function() {
      
      
      if (window.location.hostname === 'localhost') return;

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      var disqus_shortname = 'alexjinlei';
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  

      </div>
    </main>

    <footer id="footer" class="footer">
      
<div class="social-links">
      <a href="mailto:alexjinlei@email.com" class="iconfont icon-email" title="email"></a>
      <a href="https://www.linkedin.com/in/jinleizheng/" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="https://github.com/AlexJinlei" class="iconfont icon-github" title="github"></a>
  <a href="https://alexjinlei.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">AlexJinlei</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>
<script type="text/javascript" src="/dist/even.min.js?v=3.1.1"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>








</body>
</html>
